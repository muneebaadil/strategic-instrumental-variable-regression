{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "college_admissions_agent_outcomes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8r6SJk9X5Si"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1Iw2SBmmeLd"
      },
      "source": [
        "## Solve for $\\theta^*$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue-tz44NOFZB"
      },
      "source": [
        "### First, estimate theta*, true causal effect of (SAT, HS GPA) on college GPA\n",
        "## based on real data from 1000 students\n",
        "df = pd.read_csv(\"clean_gpa.csv\")\n",
        "\n",
        "x_real = df[['new_sat','new_gpa']].to_numpy()\n",
        "y_real = df['college_gpa'].to_numpy()\n",
        "\n",
        "## find true causal effects theta*\n",
        "# ordinary least squares (ols)\n",
        "x_tilde = np.hstack((x_real,np.ones((len(x_real),1)))) # add 1 for intercept\n",
        "\n",
        "m = x_real.shape[1]\n",
        "x_sum = np.zeros([m+1,m+1])\n",
        "xy_sum = np.zeros(m+1)\n",
        "\n",
        "for i in range(len(x_real)):\n",
        "  x_sum += np.outer(x_tilde[i],x_tilde[i])\n",
        "  xy_sum += x_tilde[i]*y_real[i]\n",
        "\n",
        "theta_star = np.matmul(np.linalg.inv(x_sum),xy_sum)[:-1]\n",
        "\n",
        "# set theta* to nice values for synthetic data\n",
        "theta_star = np.array([0,0.5])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOtiaWXesrPC"
      },
      "source": [
        "## Agent outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peSJ6Ae7Ffy0"
      },
      "source": [
        "def ols(x,y,T): # with intercept estimation\n",
        "  x_tilde = np.hstack((x,np.ones((len(x),1)))) # for parameter estimation\n",
        "\n",
        "  m = x.shape[1]\n",
        "  x_sum = np.zeros([m+1,m+1])\n",
        "  xy_sum = np.zeros(m+1)\n",
        "\n",
        "  for i in range(T):\n",
        "    x_sum += np.outer(x_tilde[i],x_tilde[i])\n",
        "    xy_sum += x_tilde[i]*y[i]\n",
        "\n",
        "  theta_hat_ols = np.matmul(np.linalg.inv(x_sum),xy_sum)\n",
        "  return theta_hat_ols[:m]\n",
        "\n",
        "def tsls(x,y,theta,T): # runs until round T\n",
        "  theta_tilde = np.hstack((theta,np.ones((len(theta),1)))) # for parameter estimation\n",
        "\n",
        "  m = x.shape[1]\n",
        "  theta_tilde_sum = np.zeros([m+1,m+1])\n",
        "  xtheta_tilde_sum = np.zeros([m+1,m])\n",
        "  ytheta_tilde_sum = np.zeros(m+1)\n",
        "\n",
        "  for i in range(T):\n",
        "    theta_tilde_sum += np.outer(theta_tilde[i],theta_tilde[i])\n",
        "    xtheta_tilde_sum += np.outer(theta_tilde[i],x[i])\n",
        "    ytheta_tilde_sum += theta_tilde[i]*y[i]\n",
        "\n",
        "  # Step 1) estimate Omega: regress theta onto x\n",
        "  omega_hat = np.matmul(np.linalg.inv(theta_tilde_sum),xtheta_tilde_sum)\n",
        "  z_bar = omega_hat[m,:]\n",
        "  omega_hat = omega_hat[:m,:m] \n",
        "\n",
        "  # Step 2) estimate Lambda: regress theta onto y\n",
        "  lambda_hat = np.matmul(np.linalg.inv(theta_tilde_sum),ytheta_tilde_sum)\n",
        "  gztheta_bar = lambda_hat[m]\n",
        "  lambda_hat = lambda_hat[:m]\n",
        "\n",
        "  # Step 3) estimate theta*: inverse(Omega-hat)*Lambda-hat\n",
        "  theta_hat_tsls = np.matmul(np.linalg.inv(omega_hat),lambda_hat)\n",
        "  return theta_hat_tsls"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvVOU-N-Ebuc"
      },
      "source": [
        "num_applicants = 1000\n",
        "half = int(num_applicants/2) \n",
        "\n",
        "theta_star = np.array([0, 0.5])\n",
        "m = theta_star.size\n",
        "\n",
        "sigma_g = 0.1 # g variance term\n",
        "mean_sat = 900\n",
        "mean_gpa = 2\n",
        "sigma_sat = 200\n",
        "sigma_gpa = 0.5\n",
        "\n",
        "# initial features (z)\n",
        "z = np.zeros([num_applicants,m])\n",
        "\n",
        "# disadvantaged students\n",
        "z[0:half,0] = np.random.normal(mean_sat-100,sigma_sat,z[0:half,0].shape) #SAT\n",
        "z[0:half,1] = np.random.normal(mean_gpa-.2,sigma_gpa,z[0:half,1].shape) #GPA\n",
        "\n",
        "# advantaged students\n",
        "z[half:,0] = np.random.normal(mean_sat+100,sigma_sat,z[0:half,0].shape) #SAT\n",
        "z[half:,1] = z[half:,1] + np.random.normal(mean_gpa+.2,sigma_gpa,z[half:,1].shape) #GPA\n",
        "\n",
        "z[:,0] = np.clip(z[:,0],400,1600) # clip to 400 to 1600\n",
        "z[:,1] = np.clip(z[:,1],0,4) # clip to 0 to 4.0\n",
        "\n",
        "# confounding error term g (error on true college GPA)\n",
        "g = np.ones(num_applicants)*0.5 # legacy students shifted up\n",
        "g[0:half]=-0.5 # first-gen students shifted down\n",
        "g += np.random.normal(1,0.2,size=num_applicants) # non-zero-mean\n",
        "\n",
        "# assessment rule \n",
        "theta = np.zeros([num_applicants,z.shape[1]])\n",
        "theta = np.random.normal(1,1,[num_applicants,z.shape[1]])\n",
        "theta[:,0]*=7.5 # scaling for SAT score\n",
        "\n",
        "# expected effort conversion matrices E[WW^T]\n",
        "EWWT = np.matrix([[5,0.05],[0.01,0.4]])\n",
        "\n",
        "# effort conversion matrices W_t*W_t^T\n",
        "WWT = list()\n",
        "\n",
        "for i in range(num_applicants):\n",
        "  WWT_t = EWWT.copy()\n",
        "\n",
        "  # add / subtract noise to E[WW^T]\n",
        "  noise00 = np.random.normal(EWWT[0,0]/10,EWWT[0,0]/10)\n",
        "  noise01 = np.random.normal(EWWT[0,1]/10,EWWT[0,1]/10)\n",
        "  noise10 = np.random.normal(EWWT[1,0]/10,EWWT[1,0]/10)\n",
        "  noise11 = np.random.normal(EWWT[1,1]/10,EWWT[1,1]/10)\n",
        "  noise = np.array([[noise00,noise01],[noise10,noise11]])\n",
        "\n",
        "  if i<half: # first-gen\n",
        "    WWT_t -= noise/2\n",
        "  else: # legacy\n",
        "    noise[0,0]*=7.5\n",
        "    WWT_t += noise*2\n",
        "\n",
        "  WWT.append(WWT_t)\n",
        "WWT = np.array(WWT)\n",
        "\n",
        "# observable features x\n",
        "x = np.zeros([num_applicants,z.shape[1]])\n",
        "for i in range(num_applicants):\n",
        "  x[i] = z[i] + np.matmul(WWT[i],theta[i])\n",
        "\n",
        "x[:,0] = np.clip(x[:,0],400,1600) # clip to 400 to 1600\n",
        "x[:,1] = np.clip(x[:,1],0,4) # clip to 0 to 4.0\n",
        "\n",
        "# true outcomes (college gpa)\n",
        "y = np.clip(np.matmul(x,theta_star) + g,0,4)\n",
        "\n",
        "T = len(x)\n",
        "ols_estimate = ols(x, y, T) # ols w/ intercept estimate\n",
        "tsls_estimate = tsls(x, y, theta, T) # 2sls w/ intercept estimate"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha_C80uDLJzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738387c7-2db2-4af0-eadf-dc03237470a7"
      },
      "source": [
        "## solve for true Lambda and estimated Lambda\n",
        "# regress theta_t onto y (with centering)\n",
        "m = x.shape[1]\n",
        "theta_sum = np.zeros([m,m])\n",
        "ytheta_sum = np.zeros(m)\n",
        "for i in range(T):\n",
        "  theta_centered = theta[i]-np.mean(theta[:T],axis=0)\n",
        "  theta_sum += np.outer(theta_centered,theta_centered)\n",
        "  ytheta_sum += theta_centered*(y[i]-np.mean(y[:T]))\n",
        "\n",
        "Lambda_hat = np.matmul(np.linalg.inv(theta_sum),ytheta_sum)\n",
        "print(Lambda_hat)\n",
        "\n",
        "Lambda = theta_star*EWWT\n",
        "Lambda = np.array([Lambda[0,0],Lambda[0,1]]) # recast into vector\n",
        "print(Lambda)\n",
        "\n",
        "print(np.linalg.norm(Lambda_hat-Lambda))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00210626 0.24546243]\n",
            "[0.005 0.2  ]\n",
            "0.045554427111434516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4RQIKNsBJ1Z",
        "outputId": "2ab1da88-f07a-40d5-a063-7a10ff0d19ad"
      },
      "source": [
        "## solve for AO maximizing theta (theta_ao)\n",
        "\n",
        "# solve for true Lambda and estimated Lambda\n",
        "# by regressing theta_t onto y (with centering)\n",
        "m = x.shape[1]\n",
        "theta_sum = np.zeros([m,m])\n",
        "ytheta_sum = np.zeros(m)\n",
        "for i in range(T):\n",
        "  theta_centered = theta[i]-np.mean(theta[:T],axis=0)\n",
        "  theta_sum += np.outer(theta_centered,theta_centered)\n",
        "  ytheta_sum += theta_centered*(y[i]-np.mean(y[:T]))\n",
        "\n",
        "Lambda_hat = np.matmul(np.linalg.inv(theta_sum),ytheta_sum)\n",
        "print(Lambda_hat)\n",
        "\n",
        "Lambda = np.matmul(EWWT,theta_star)\n",
        "Lambda = np.array([Lambda[0,0],Lambda[0,1]]) # recast into vector\n",
        "\n",
        "# solve LP with Lambda and its estimate (Lambda_hat)\n",
        "c1 = [-Lambda[0], -Lambda[1]]\n",
        "c2 = [-Lambda_hat[0], -Lambda_hat[1]]\n",
        "A = [[1, 1]]\n",
        "b = [10]\n",
        "theta0_bounds = (-30, 30)\n",
        "theta1_bounds = (-3, 3)\n",
        "from scipy.optimize import linprog\n",
        "opt1 = linprog(c1, A_ub=A, b_ub=b, bounds=[theta0_bounds, theta1_bounds])\n",
        "opt2 = linprog(c2, A_ub=A, b_ub=b, bounds=[theta0_bounds, theta1_bounds])\n",
        "\n",
        "theta_ao = opt1.x\n",
        "theta_ao_hat = opt2.x"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00210626 0.24546243]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU8DBhTCVXRV",
        "outputId": "d4a705dd-3659-44ae-c9d0-1c9d91deb6e2"
      },
      "source": [
        "import cvxpy as cp\n",
        "\n",
        "# Solve for true agent outcomes-maximizing theta_ao\n",
        "theta_ao = cp.Variable((len(Lambda)))\n",
        "\n",
        "# Create two constraints.\n",
        "constraints = [theta_ao[0] >= -30, theta_ao[0] <= 30,\n",
        "               theta_ao[1] >= -3, theta_ao[1] <= 3,\n",
        "               cp.norm(theta_ao) <= 10]\n",
        "\n",
        "# Form objective.\n",
        "obj = cp.Maximize(cp.matmul(theta_ao,Lambda))\n",
        "\n",
        "# Form and solve problem.\n",
        "prob = cp.Problem(obj, constraints)\n",
        "prob.solve()  # Returns the optimal value."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8384848001803566"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbOMsQuWSCrr",
        "outputId": "b0c587c2-a523-44d2-887f-dcdf84978e19"
      },
      "source": [
        "# Solve for estimated agent outcomes-maximizing theta_ao_hat \n",
        "# (using estimate theta_star_hat\n",
        "theta_ao_hat = cp.Variable((len(Lambda_hat)))\n",
        "\n",
        "# Create two constraints.\n",
        "constraints = [theta_ao_hat[0] >= -30, theta_ao_hat[0] <= 30,\n",
        "               theta_ao_hat[1] >= -3, theta_ao_hat[1] <= 3,\n",
        "               cp.norm(theta_ao_hat) <= 10]\n",
        "\n",
        "# Form objective.\n",
        "obj = cp.Maximize(cp.matmul(theta_ao_hat,Lambda_hat))\n",
        "\n",
        "# Form and solve problem.\n",
        "prob = cp.Problem(obj, constraints)\n",
        "prob.solve()  # Returns the optimal value."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.756479715128524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iVeJh4RR80H",
        "outputId": "3748a2b7-f666-4f59-a212-3ca400ee07dd"
      },
      "source": [
        "# agent outcomes for different theta\n",
        "theta_ols = ols(x,y,len(x)) # ols estimate of theta\n",
        "\n",
        "# initialize lists of x's\n",
        "x_star = np.zeros([num_applicants,z.shape[1]])\n",
        "x_ols = np.zeros([num_applicants,z.shape[1]])\n",
        "x_ao = np.zeros([num_applicants,z.shape[1]])\n",
        "x_ao_hat = np.zeros([num_applicants,z.shape[1]])\n",
        "\n",
        "for i in range(num_applicants):\n",
        "  x_star[i] = z[i] + np.matmul(WWT[i],theta_star)\n",
        "  x_ols[i] = z[i] + np.matmul(WWT[i],theta_ols)\n",
        "  x_ao[i] = z[i] + np.matmul(WWT[i],theta_ao.value)\n",
        "  x_ao_hat[i] = z[i] + np.matmul(WWT[i],theta_ao_hat.value)\n",
        "\n",
        "# clip x values\n",
        "def clip_x(x):\n",
        "  x[:,0] = np.clip(x[:,0],400,1600) # clip to [400, 1600]\n",
        "  x[:,1] = np.clip(x[:,1],0,4) # clip to [0, 4]\n",
        "  return x\n",
        "\n",
        "x_star = clip_x(x_star)\n",
        "x_ols = clip_x(x_ols)\n",
        "x_ao = clip_x(x_ao)\n",
        "x_ao_hat = clip_x(x_ao_hat)\n",
        "\n",
        "# true outcomes (college gpa)\n",
        "y_star = np.clip(np.matmul(x_star,theta_star) + g, 0, 4)\n",
        "y_ols = np.clip(np.matmul(x_ols,theta_star) + g, 0, 4)\n",
        "y_ao = np.clip(np.matmul(x_ao,theta_star) + g, 0, 4)\n",
        "y_ao_hat = np.clip(np.matmul(x_ao_hat,theta_star) + g, 0, 4)\n",
        "\n",
        "print(\"Mean reward playing theta*:\", np.mean(y_star))\n",
        "print(\"Mean reward playing theta_hat (OLS):\",np.mean(y_ols))\n",
        "print(\"Mean reward playing theta_ao (w/ true Lambda):\",np.mean(y_ao))\n",
        "print(\"Mean reward playing theta_ao_hat (w/ estimated Lambda_hat):\",np.mean(y_ao_hat))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward playing theta*: 2.1028671413250057\n",
            "Mean reward playing theta_hat (OLS): 2.154948137128592\n",
            "Mean reward playing theta_ao (w/ true Lambda): 2.6594687137431166\n",
            "Mean reward playing theta_ao_hat (w/ estimated Lambda_hat): 2.6594687137567434\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}